{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "        \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n",
    "random.seed(42)\n",
    "# ---------------------- 1. 数据加载与归一化 ----------------------\n",
    "# CSV 文件包含的特征\n",
    "feature_cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "                \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "\n",
    "data = pd.read_csv('diabetes_dataset_1.csv')\n",
    "\n",
    "# 对所有特征进行 min–max 归一化\n",
    "data_norm = data.copy()\n",
    "for col in feature_cols:\n",
    "    min_val = data[col].min()\n",
    "    max_val = data[col].max()\n",
    "    data_norm[col] = (data[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "# ---------------------- 2. 利用 ReliefF 自动计算特征重要性 ----------------------\n",
    "# 需要安装 skrebate：pip install skrebate\n",
    "from skrebate import ReliefF\n",
    "\n",
    "X = data_norm[feature_cols].values\n",
    "y = data_norm['Outcome'].values\n",
    "\n",
    "# 初始化 ReliefF 算法（邻居数设为10）\n",
    "relief = ReliefF(n_neighbors=10)\n",
    "relief.fit(X, y)\n",
    "importance_scores = relief.feature_importances_\n",
    "\n",
    "# 按照重要性降序排列，得到特征名称排序\n",
    "ordered_indices = np.argsort(importance_scores)[::-1]\n",
    "ordered_features = [feature_cols[i] for i in ordered_indices]\n",
    "print(\"ReliefF 计算的特征重要性排序：\", ordered_features)\n",
    "\n",
    "# ---------------------- 3. 根据排序自动生成区域映射 ----------------------\n",
    "# 定义预先设计好的区域列表，按面积从大到小排列（格式：(x, y, width, height)）\n",
    "predefined_regions = [\n",
    "    (0, 0, 80, 80),    # 面积：80x80=6400，分配给最重要的特征\n",
    "    (80, 0, 40, 60),   # 面积：40x60=2400\n",
    "    (0, 80, 50, 40),   # 面积：50x40=2000\n",
    "    (50, 80, 40, 30),  # 面积：40x30=1200\n",
    "    (80, 60, 40, 20),  # 面积：40x20=800\n",
    "    (90, 80, 30, 20),  # 面积：30x20=600\n",
    "    (50, 110, 25, 10), # 面积：25x10=250\n",
    "    (75, 110, 20, 10)  # 面积：20x10=200\n",
    "]\n",
    "\n",
    "self_region_mapping = {\n",
    "    \"Age\": (0, 0, 69, 60),                     # Feature_7\n",
    "    \"SkinThickness\": (69, 0, 51, 60),          # Feature_3\n",
    "    \"BMI\": (0, 60, 59, 40),                    # Feature_5\n",
    "    \"Pregnancies\": (59, 60, 32, 40),           # Feature_0\n",
    "    \"Insulin\": (91, 60, 29, 40),               # Feature_4\n",
    "    \"DiabetesPedigreeFunction\": (0, 100, 75, 20),  # Feature_6\n",
    "    \"BloodPressure\": (75, 100, 39, 20),        # Feature_2\n",
    "    \"Glucose\": (114, 100, 6, 20)               # Feature_1\n",
    "}\n",
    "\n",
    "# 自动将预定义区域分配给排序后的特征\n",
    "auto_region_mapping = {}\n",
    "for i, feat in enumerate(ordered_features):\n",
    "    auto_region_mapping[feat] = predefined_regions[i]\n",
    "\n",
    "print(\"自动生成的区域映射：\")\n",
    "for feat, region in auto_region_mapping.items():\n",
    "    print(f\"{feat}: {region}\")\n",
    "\n",
    "\n",
    "def create_image_from_features(sample, region_mapping):\n",
    "    \"\"\"\n",
    "    根据单个样本的归一化特征和给定的 region_mapping 生成 120x120 灰度图像\n",
    "    \"\"\"\n",
    "    img = Image.new('L', (120, 120), color=0)  # 创建黑底图\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 对于每个特征，根据 mapping 中的区域将值映射到 0-255 灰度值\n",
    "    for feat in feature_cols:\n",
    "        val = int(sample[feat] * 255)\n",
    "        if feat in region_mapping:\n",
    "            x, y, w, h = region_mapping[feat]\n",
    "            draw.rectangle([x, y, x + w, y + h], fill=val)\n",
    "    return img\n",
    "\n",
    "# 可视化查看一个样本转换后的图像\n",
    "sample_img = create_image_from_features(data_norm.iloc[0], auto_region_mapping)\n",
    "plt.imshow(sample_img, cmap='gray')\n",
    "plt.title(\"Sample Converted Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# ---------------------- 5. 定义 PyTorch 数据集 ----------------------\n",
    "class PimaImageDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        \"\"\"\n",
    "        df：包含归一化特征及 Outcome 的 DataFrame\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]\n",
    "        label = int(self.y[idx])\n",
    "        # 如果 transform 已经设置，则直接应用\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        # 否则，如果 img 不是 tensor，则转换为 tensor；如果已经是 tensor，则直接返回\n",
    "        elif not torch.is_tensor(img):\n",
    "            img = transforms.ToTensor()(img)\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 6. 数据增强与数据加载器 ----------------------\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "# 一维转二维\n",
    "def changeToTwoD(dataset, region_mapping):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for idx in range(dataset.shape[0]):\n",
    "        img = convert_to_rgb(create_image_from_features(dataset.iloc[idx], region_mapping))\n",
    "\n",
    "        resize = transforms.Resize(size=(224, 224))\n",
    "        img = resize.forward(img)\n",
    "\n",
    "        label = int(dataset.iloc[idx]['Outcome'])\n",
    "        features.append(img)\n",
    "        labels.append(label)\n",
    "    return features, labels\n",
    "\n",
    "# 这里对2D图像通过几何变换进行数据增广\n",
    "def create_artificial_records(img_features, img_labels):\n",
    "    artificial_features = []\n",
    "    artificial_labels = []\n",
    "    for i, imfe in enumerate(img_features):\n",
    "\n",
    "        img = [0] * 4\n",
    "\n",
    "        flip = transforms.RandomHorizontalFlip(p=1)\n",
    "        rotate = transforms.RandomRotation(30)\n",
    "        scale = transforms.Resize(size=(int(120 * random.uniform(0.9,1.1)), int(120 * random.uniform(0.9,1.1))))\n",
    "        translate = transforms.RandomAffine(0, translate=(0.1, 0.1))\n",
    "\n",
    "        resize = transforms.Resize(size=(224, 224))\n",
    "\n",
    "        img[0] = flip.forward(imfe)\n",
    "        img[1] = rotate.forward(imfe)\n",
    "        img[2] = scale.forward(imfe)\n",
    "        img[3] = translate.forward(imfe)\n",
    "        img = [resize.forward(_im) for _im in img]\n",
    "        artificial_features += img\n",
    "        artificial_labels += [img_labels[i]] * 4\n",
    "    return artificial_features, artificial_labels\n",
    "\n",
    "img_features, img_labels = changeToTwoD(data_norm, auto_region_mapping)\n",
    "aug_img_features, aug_img_labels = create_artificial_records(img_features, img_labels)\n",
    "all_features = img_features + aug_img_features\n",
    "all_labels = img_labels + aug_img_labels\n",
    "\n",
    "# 下面还要改改\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_features, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = PimaImageDataset(X_train, y_train)\n",
    "test_dataset = PimaImageDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# ---------------------- 7. 定义并微调预训练的 ResNet18 模型 ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # 两分类任务\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "num_epochs = 10\n",
    "print(\"----- 初始训练 -----\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for imgs, labels in train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "    epoch_loss = running_loss / total_train\n",
    "    train_acc = correct_train / total_train * 100\n",
    "    \n",
    "    \n",
    "     # 测试集评估\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_test_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "    test_loss = running_test_loss / total_test\n",
    "    test_acc = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.2f}%\")\n",
    "    # print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "\n",
    "##############################################\n",
    "# 5. 从初始训练中提取误分类图片并复制（仅复制原样，不做内部微调）\n",
    "##############################################\n",
    "model.eval()\n",
    "misclassified_imgs = []\n",
    "misclassified_labels = []\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "final_test_acc = correct / total * 100\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for i in range(len(labels)):\n",
    "            if preds[i] != labels[i]:\n",
    "                # 将误分类图片直接复制（原样，不进行变换）\n",
    "                misclassified_imgs.append(imgs[i].cpu())\n",
    "                misclassified_labels.append(labels[i].cpu())\n",
    "\n",
    "\n",
    "print(f\"在训练集中发现误分类图片数：{len(misclassified_imgs)}\")\n",
    "\n",
    "# 此处仅复制原样，不进行几何变换\n",
    "additional_imgs = misclassified_imgs.copy()\n",
    "additional_labels = [int(lbl) for lbl in misclassified_labels]\n",
    "\n",
    "print(f\"增强生成的额外样本数：{len(additional_imgs)}\")\n",
    "\n",
    "# 从原始训练数据集中提取所有图像（以 tensor 形式）\n",
    "original_train_imgs = []\n",
    "original_train_labels = []\n",
    "for img, label in train_loader.dataset:\n",
    "    original_train_imgs.append(img)\n",
    "    original_train_labels.append(label)\n",
    "\n",
    "# 合并原始训练集与复制的误分类图片\n",
    "new_train_imgs = original_train_imgs + additional_imgs\n",
    "new_train_labels = original_train_labels + additional_labels\n",
    "\n",
    "# 构造新的训练集\n",
    "new_train_dataset = PimaImageDataset(new_train_imgs, new_train_labels)\n",
    "new_train_loader = DataLoader(new_train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "\n",
    "##############################################\n",
    "# 6. 使用包含误分类复制样本的新训练集重新训练模型\n",
    "##############################################\n",
    "num_additional_epochs = 10\n",
    "print(\"----- 重新训练：使用增强后的训练集 -----\")\n",
    "for epoch in range(num_additional_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for imgs, labels in new_train_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(imgs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total * 100\n",
    "    \n",
    "    \n",
    "     # 测试集评估\n",
    "    model.eval()\n",
    "    running_test_loss = 0.0\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_test_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (preds == labels).sum().item()\n",
    "    test_loss = running_test_loss / total_test\n",
    "    test_acc = correct_test / total_test * 100\n",
    "    \n",
    "    print(f\"Additional Epoch {epoch+1}/{num_additional_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Loss: {test_loss:.4f} - Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # print(f\"Additional Epoch {epoch+1}/{num_additional_epochs} - Loss: {epoch_loss:.4f} - Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "##############################################\n",
    "# 7. 最终评估模型在测试集上的性能\n",
    "##############################################\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        outputs = model(imgs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (preds == labels).sum().item()\n",
    "final_test_acc = correct / total * 100\n",
    "print(f\"Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------- 10. 绘制指标曲线 ----------------------\n",
    "epochs = range(1, num_epochs + 1)\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# 绘制 Loss 曲线\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_loss_list, 'b-', label='Train Loss')\n",
    "plt.plot(epochs, test_loss_list, 'r-', label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Train and Test Loss over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制 Accuracy 曲线\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_acc_list, 'b-', label='Train Accuracy')\n",
    "plt.plot(epochs, test_acc_list, 'r-', label='Test Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Train and Test Accuracy over Epochs')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ---------------------- 11. 可视化部分 ----------------------\n",
    "model.eval()\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter)\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "outputs = model(images)\n",
    "_, preds = torch.max(outputs, 1)\n",
    "\n",
    "images_np = images.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "batch_size = images_np.shape[0]\n",
    "cols = 8\n",
    "rows = batch_size // cols if batch_size % cols == 0 else batch_size // cols + 1\n",
    "plt.figure(figsize=(15, 2.5 * rows))\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(images_np[i])\n",
    "    plt.title(f\"Pred: {preds[i].item()}\\nTrue: {labels[i].item()}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
