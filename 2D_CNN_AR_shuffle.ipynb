{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状: (768, 9)\n",
      "人工记录形状: (10000, 9)\n",
      "合并后的数据形状: (10768, 9)\n",
      "ReliefF 计算的特征重要性排序： ['DiabetesPedigreeFunction', 'Age', 'BMI', 'BloodPressure', 'Pregnancies', 'Glucose', 'Insulin', 'SkinThickness']\n",
      "自动生成的区域映射：\n",
      "DiabetesPedigreeFunction: (0, 0, 80, 80)\n",
      "Age: (80, 0, 40, 60)\n",
      "BMI: (0, 80, 50, 40)\n",
      "BloodPressure: (50, 80, 40, 30)\n",
      "Pregnancies: (80, 60, 40, 20)\n",
      "Glucose: (90, 80, 30, 20)\n",
      "Insulin: (50, 110, 25, 10)\n",
      "SkinThickness: (75, 110, 20, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- 第 1 次划分 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Split 1 - Epoch 1/20 - Loss: 0.5478 - Train Acc: 70.86% - Test Acc: 75.97%\n",
      "Split 1 - Epoch 2/20 - Loss: 0.4208 - Train Acc: 80.81% - Test Acc: 79.22%\n",
      "Split 1 - Epoch 3/20 - Loss: 0.3637 - Train Acc: 83.05% - Test Acc: 81.17%\n",
      "Split 1 - Epoch 4/20 - Loss: 0.3341 - Train Acc: 84.63% - Test Acc: 78.57%\n",
      "Split 1 - Epoch 5/20 - Loss: 0.3003 - Train Acc: 86.51% - Test Acc: 78.57%\n",
      "Split 1 - Epoch 6/20 - Loss: 0.2784 - Train Acc: 86.94% - Test Acc: 86.36%\n",
      "Split 1 - Epoch 7/20 - Loss: 0.2484 - Train Acc: 89.21% - Test Acc: 87.66%\n",
      "Split 1 - Epoch 8/20 - Loss: 0.2236 - Train Acc: 90.37% - Test Acc: 85.06%\n",
      "Split 1 - Epoch 9/20 - Loss: 0.2069 - Train Acc: 91.12% - Test Acc: 89.61%\n",
      "Split 1 - Epoch 10/20 - Loss: 0.1853 - Train Acc: 92.11% - Test Acc: 92.21%\n",
      "Split 1 - Epoch 11/20 - Loss: 0.1622 - Train Acc: 93.25% - Test Acc: 91.56%\n",
      "Split 1 - Epoch 12/20 - Loss: 0.1477 - Train Acc: 93.84% - Test Acc: 96.10%\n",
      "Split 1 - Epoch 13/20 - Loss: 0.1350 - Train Acc: 94.39% - Test Acc: 93.51%\n",
      "Split 1 - Epoch 14/20 - Loss: 0.1199 - Train Acc: 95.11% - Test Acc: 96.10%\n",
      "Split 1 - Epoch 15/20 - Loss: 0.1018 - Train Acc: 96.02% - Test Acc: 93.51%\n",
      "Split 1 - Epoch 16/20 - Loss: 0.1031 - Train Acc: 96.02% - Test Acc: 93.51%\n",
      "Split 1 - Epoch 17/20 - Loss: 0.0843 - Train Acc: 96.69% - Test Acc: 95.45%\n",
      "Split 1 - Epoch 18/20 - Loss: 0.0894 - Train Acc: 96.72% - Test Acc: 98.05%\n",
      "Split 1 - Epoch 19/20 - Loss: 0.0768 - Train Acc: 97.19% - Test Acc: 96.10%\n",
      "Split 1 - Epoch 20/20 - Loss: 0.0761 - Train Acc: 97.06% - Test Acc: 94.16%\n",
      "Split 1 Final Test Accuracy: 94.16%\n",
      "\n",
      "---------------- 第 2 次划分 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Split 2 - Epoch 1/20 - Loss: 0.5433 - Train Acc: 71.27% - Test Acc: 77.92%\n",
      "Split 2 - Epoch 2/20 - Loss: 0.4171 - Train Acc: 79.98% - Test Acc: 75.97%\n",
      "Split 2 - Epoch 3/20 - Loss: 0.3731 - Train Acc: 82.15% - Test Acc: 79.87%\n",
      "Split 2 - Epoch 4/20 - Loss: 0.3355 - Train Acc: 84.17% - Test Acc: 81.17%\n",
      "Split 2 - Epoch 5/20 - Loss: 0.3011 - Train Acc: 86.32% - Test Acc: 84.42%\n",
      "Split 2 - Epoch 6/20 - Loss: 0.2655 - Train Acc: 87.78% - Test Acc: 86.36%\n",
      "Split 2 - Epoch 7/20 - Loss: 0.2422 - Train Acc: 89.07% - Test Acc: 84.42%\n",
      "Split 2 - Epoch 8/20 - Loss: 0.2086 - Train Acc: 91.07% - Test Acc: 92.86%\n",
      "Split 2 - Epoch 9/20 - Loss: 0.1973 - Train Acc: 91.31% - Test Acc: 89.61%\n",
      "Split 2 - Epoch 10/20 - Loss: 0.1820 - Train Acc: 92.10% - Test Acc: 89.61%\n",
      "Split 2 - Epoch 11/20 - Loss: 0.1647 - Train Acc: 93.21% - Test Acc: 90.91%\n",
      "Split 2 - Epoch 12/20 - Loss: 0.1387 - Train Acc: 94.55% - Test Acc: 95.45%\n",
      "Split 2 - Epoch 13/20 - Loss: 0.1308 - Train Acc: 94.72% - Test Acc: 94.16%\n",
      "Split 2 - Epoch 14/20 - Loss: 0.1183 - Train Acc: 95.30% - Test Acc: 90.91%\n",
      "Split 2 - Epoch 15/20 - Loss: 0.1167 - Train Acc: 95.47% - Test Acc: 94.16%\n",
      "Split 2 - Epoch 16/20 - Loss: 0.1055 - Train Acc: 95.92% - Test Acc: 92.21%\n",
      "Split 2 - Epoch 17/20 - Loss: 0.0903 - Train Acc: 96.48% - Test Acc: 94.81%\n",
      "Split 2 - Epoch 18/20 - Loss: 0.0857 - Train Acc: 96.67% - Test Acc: 96.10%\n",
      "Split 2 - Epoch 19/20 - Loss: 0.0838 - Train Acc: 96.78% - Test Acc: 95.45%\n",
      "Split 2 - Epoch 20/20 - Loss: 0.0645 - Train Acc: 97.73% - Test Acc: 97.40%\n",
      "Split 2 Final Test Accuracy: 97.40%\n",
      "\n",
      "---------------- 第 3 次划分 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Split 3 - Epoch 1/20 - Loss: 0.5535 - Train Acc: 70.83% - Test Acc: 68.83%\n",
      "Split 3 - Epoch 2/20 - Loss: 0.4302 - Train Acc: 79.89% - Test Acc: 77.27%\n",
      "Split 3 - Epoch 3/20 - Loss: 0.3762 - Train Acc: 82.09% - Test Acc: 83.12%\n",
      "Split 3 - Epoch 4/20 - Loss: 0.3426 - Train Acc: 83.54% - Test Acc: 77.92%\n",
      "Split 3 - Epoch 5/20 - Loss: 0.3087 - Train Acc: 85.52% - Test Acc: 79.87%\n",
      "Split 3 - Epoch 6/20 - Loss: 0.2853 - Train Acc: 86.74% - Test Acc: 84.42%\n",
      "Split 3 - Epoch 7/20 - Loss: 0.2566 - Train Acc: 88.15% - Test Acc: 91.56%\n",
      "Split 3 - Epoch 8/20 - Loss: 0.2328 - Train Acc: 89.53% - Test Acc: 81.82%\n",
      "Split 3 - Epoch 9/20 - Loss: 0.2141 - Train Acc: 90.76% - Test Acc: 87.66%\n",
      "Split 3 - Epoch 10/20 - Loss: 0.1939 - Train Acc: 91.70% - Test Acc: 89.61%\n",
      "Split 3 - Epoch 11/20 - Loss: 0.1674 - Train Acc: 92.91% - Test Acc: 92.86%\n",
      "Split 3 - Epoch 12/20 - Loss: 0.1461 - Train Acc: 93.72% - Test Acc: 88.96%\n",
      "Split 3 - Epoch 13/20 - Loss: 0.1410 - Train Acc: 94.18% - Test Acc: 92.86%\n",
      "Split 3 - Epoch 14/20 - Loss: 0.1207 - Train Acc: 95.18% - Test Acc: 92.86%\n",
      "Split 3 - Epoch 15/20 - Loss: 0.1143 - Train Acc: 95.60% - Test Acc: 90.91%\n",
      "Split 3 - Epoch 16/20 - Loss: 0.1089 - Train Acc: 95.80% - Test Acc: 95.45%\n",
      "Split 3 - Epoch 17/20 - Loss: 0.0942 - Train Acc: 96.35% - Test Acc: 92.86%\n",
      "Split 3 - Epoch 18/20 - Loss: 0.0852 - Train Acc: 96.90% - Test Acc: 96.75%\n",
      "Split 3 - Epoch 19/20 - Loss: 0.0745 - Train Acc: 96.99% - Test Acc: 96.75%\n",
      "Split 3 - Epoch 20/20 - Loss: 0.0838 - Train Acc: 96.92% - Test Acc: 92.21%\n",
      "Split 3 Final Test Accuracy: 92.21%\n",
      "\n",
      "---------------- 第 4 次划分 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Split 4 - Epoch 1/20 - Loss: 0.5550 - Train Acc: 70.93% - Test Acc: 71.43%\n",
      "Split 4 - Epoch 2/20 - Loss: 0.4294 - Train Acc: 79.84% - Test Acc: 64.29%\n",
      "Split 4 - Epoch 3/20 - Loss: 0.3659 - Train Acc: 82.95% - Test Acc: 80.52%\n",
      "Split 4 - Epoch 4/20 - Loss: 0.3289 - Train Acc: 85.09% - Test Acc: 80.52%\n",
      "Split 4 - Epoch 5/20 - Loss: 0.3034 - Train Acc: 86.22% - Test Acc: 75.32%\n",
      "Split 4 - Epoch 6/20 - Loss: 0.2657 - Train Acc: 88.03% - Test Acc: 78.57%\n",
      "Split 4 - Epoch 7/20 - Loss: 0.2433 - Train Acc: 89.02% - Test Acc: 83.12%\n",
      "Split 4 - Epoch 8/20 - Loss: 0.2237 - Train Acc: 90.05% - Test Acc: 89.61%\n",
      "Split 4 - Epoch 9/20 - Loss: 0.2152 - Train Acc: 90.72% - Test Acc: 90.26%\n",
      "Split 4 - Epoch 10/20 - Loss: 0.1830 - Train Acc: 92.44% - Test Acc: 91.56%\n",
      "Split 4 - Epoch 11/20 - Loss: 0.1516 - Train Acc: 93.77% - Test Acc: 95.45%\n",
      "Split 4 - Epoch 12/20 - Loss: 0.1603 - Train Acc: 93.26% - Test Acc: 89.61%\n",
      "Split 4 - Epoch 13/20 - Loss: 0.1282 - Train Acc: 94.87% - Test Acc: 92.86%\n",
      "Split 4 - Epoch 14/20 - Loss: 0.1299 - Train Acc: 94.83% - Test Acc: 92.86%\n",
      "Split 4 - Epoch 15/20 - Loss: 0.1182 - Train Acc: 95.29% - Test Acc: 92.86%\n",
      "Split 4 - Epoch 16/20 - Loss: 0.0997 - Train Acc: 96.22% - Test Acc: 94.81%\n",
      "Split 4 - Epoch 17/20 - Loss: 0.0981 - Train Acc: 96.21% - Test Acc: 95.45%\n",
      "Split 4 - Epoch 18/20 - Loss: 0.0853 - Train Acc: 96.72% - Test Acc: 96.75%\n",
      "Split 4 - Epoch 19/20 - Loss: 0.0943 - Train Acc: 96.22% - Test Acc: 97.40%\n",
      "Split 4 - Epoch 20/20 - Loss: 0.0843 - Train Acc: 96.67% - Test Acc: 98.05%\n",
      "Split 4 Final Test Accuracy: 98.05%\n",
      "\n",
      "---------------- 第 5 次划分 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Split 5 - Epoch 1/20 - Loss: 0.5545 - Train Acc: 70.47% - Test Acc: 76.62%\n",
      "Split 5 - Epoch 2/20 - Loss: 0.4324 - Train Acc: 80.01% - Test Acc: 80.52%\n",
      "Split 5 - Epoch 3/20 - Loss: 0.3766 - Train Acc: 82.46% - Test Acc: 83.77%\n",
      "Split 5 - Epoch 4/20 - Loss: 0.3338 - Train Acc: 84.46% - Test Acc: 85.71%\n",
      "Split 5 - Epoch 5/20 - Loss: 0.3185 - Train Acc: 85.30% - Test Acc: 87.66%\n",
      "Split 5 - Epoch 6/20 - Loss: 0.2824 - Train Acc: 87.16% - Test Acc: 88.31%\n",
      "Split 5 - Epoch 7/20 - Loss: 0.2567 - Train Acc: 88.64% - Test Acc: 92.21%\n",
      "Split 5 - Epoch 8/20 - Loss: 0.2374 - Train Acc: 89.61% - Test Acc: 96.10%\n",
      "Split 5 - Epoch 9/20 - Loss: 0.2072 - Train Acc: 91.07% - Test Acc: 88.31%\n",
      "Split 5 - Epoch 10/20 - Loss: 0.1945 - Train Acc: 91.62% - Test Acc: 88.96%\n",
      "Split 5 - Epoch 11/20 - Loss: 0.1889 - Train Acc: 91.79% - Test Acc: 92.86%\n",
      "Split 5 - Epoch 12/20 - Loss: 0.1546 - Train Acc: 93.56% - Test Acc: 92.21%\n",
      "Split 5 - Epoch 13/20 - Loss: 0.1442 - Train Acc: 94.24% - Test Acc: 94.81%\n",
      "Split 5 - Epoch 14/20 - Loss: 0.1294 - Train Acc: 94.83% - Test Acc: 95.45%\n",
      "Split 5 - Epoch 15/20 - Loss: 0.1201 - Train Acc: 95.31% - Test Acc: 96.75%\n",
      "Split 5 - Epoch 16/20 - Loss: 0.1128 - Train Acc: 95.40% - Test Acc: 96.75%\n",
      "Split 5 - Epoch 17/20 - Loss: 0.0933 - Train Acc: 96.33% - Test Acc: 98.05%\n",
      "Split 5 - Epoch 18/20 - Loss: 0.0933 - Train Acc: 96.56% - Test Acc: 96.75%\n",
      "Split 5 - Epoch 19/20 - Loss: 0.0920 - Train Acc: 96.28% - Test Acc: 98.05%\n",
      "Split 5 - Epoch 20/20 - Loss: 0.0753 - Train Acc: 97.11% - Test Acc: 96.75%\n",
      "Split 5 Final Test Accuracy: 96.75%\n",
      "\n",
      "---------------- 五次划分测试结果 ----------------\n",
      "Split 1: Test Accuracy = 94.16%\n",
      "Split 2: Test Accuracy = 97.40%\n",
      "Split 3: Test Accuracy = 92.21%\n",
      "Split 4: Test Accuracy = 98.05%\n",
      "Split 5: Test Accuracy = 96.75%\n",
      "Average Test Accuracy: 95.71%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# ===================== Artificial Record 数据处理 =====================\n",
    "def create_artificial_records(dataset, num_artificial_records=10000):\n",
    "    artificial_records = []\n",
    "    \n",
    "    # 将数据按 Outcome 分为糖尿病和非糖尿病\n",
    "    diabetic = dataset[dataset[:, -1] == 1]\n",
    "    non_diabetic = dataset[dataset[:, -1] == 0]\n",
    "    \n",
    "    for partition in [diabetic, non_diabetic]:\n",
    "        # 根据年龄分组：小于40为年轻组，大于等于40为年长组\n",
    "        young = partition[partition[:, -2] < 40]\n",
    "        old = partition[partition[:, -2] >= 40]\n",
    "        \n",
    "        for age_group in [young, old]:\n",
    "            # 分为孕妇组和非孕妇组（孕次>0为孕妇）\n",
    "            pregnant = age_group[age_group[:, 0] > 0]\n",
    "            non_pregnant = age_group[age_group[:, 0] == 0]\n",
    "            \n",
    "            for group in [pregnant, non_pregnant]:\n",
    "                if len(group) > 0:  # 确保组非空\n",
    "                    for _ in range(num_artificial_records // 8):\n",
    "                        new_record = group[np.random.randint(len(group))].copy()\n",
    "                        \n",
    "                        # 在 Glucose 和 Insulin 上做微小调整（保持反比关系）\n",
    "                        glucose_change = np.random.uniform(-10, 10)\n",
    "                        new_record[1] += glucose_change\n",
    "                        new_record[4] -= glucose_change * 0.5\n",
    "                        \n",
    "                        # 在 SkinThickness 和 BMI 上做微小调整\n",
    "                        skin_change = np.random.uniform(-5, 5)\n",
    "                        new_record[3] += skin_change\n",
    "                        new_record[5] += skin_change * 0.1\n",
    "                        \n",
    "                        artificial_records.append(new_record)\n",
    "    \n",
    "    return np.array(artificial_records)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# ---------------------- 0. 数据加载与清洗 ----------------------\n",
    "# 假设文件中列顺序为：Pregnancies, Glucose, BloodPressure, SkinThickness,\n",
    "# Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome\n",
    "data = pd.read_csv('diabetes_dataset_1.csv')\n",
    "\n",
    "# 将部分特征中可能出现的0（视为缺失值）替换为中位数\n",
    "cols_to_replace = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "for col in cols_to_replace:\n",
    "    data[col] = data[col].replace(0, np.nan)\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# ---------------------- 1. 生成原始数据与人工记录，并合并数据 ----------------------\n",
    "# 将原始数据转换为 numpy 数组\n",
    "dataset_np = data.values\n",
    "print(\"原始数据形状:\", dataset_np.shape)\n",
    "\n",
    "# 生成人工记录（基于原始数据生成）\n",
    "artificial_dataset = create_artificial_records(dataset_np)\n",
    "print(\"人工记录形状:\", artificial_dataset.shape)\n",
    "\n",
    "# 合并原始数据和部分人工记录（此处只取前 10000 条人工记录）\n",
    "combined_dataset_np = np.vstack((dataset_np, artificial_dataset[:10000]))\n",
    "print(\"合并后的数据形状:\", combined_dataset_np.shape)\n",
    "\n",
    "# 转换为 DataFrame，并保持原有列名\n",
    "combined_data = pd.DataFrame(combined_dataset_np, columns=data.columns)\n",
    "\n",
    "# ---------------------- 2. 对所有特征进行 min–max 归一化 ----------------------\n",
    "# 仅对特征列归一化，Outcome 保持不变\n",
    "feature_cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "                \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "\n",
    "data_norm = combined_data.copy()\n",
    "for col in feature_cols:\n",
    "    min_val = data_norm[col].min()\n",
    "    max_val = data_norm[col].max()\n",
    "    data_norm[col] = (data_norm[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "# ---------------------- 3. 利用 ReliefF 计算特征重要性 ----------------------\n",
    "# 需安装 skrebate：pip install skrebate\n",
    "from skrebate import ReliefF\n",
    "\n",
    "X = data_norm[feature_cols].values\n",
    "y = data_norm['Outcome'].values.astype(int)\n",
    "\n",
    "relief = ReliefF(n_neighbors=10)\n",
    "relief.fit(X, y)\n",
    "importance_scores = relief.feature_importances_\n",
    "\n",
    "# 按重要性降序排列，得到特征名称排序\n",
    "ordered_indices = np.argsort(importance_scores)[::-1]\n",
    "ordered_features = [feature_cols[i] for i in ordered_indices]\n",
    "print(\"ReliefF 计算的特征重要性排序：\", ordered_features)\n",
    "\n",
    "# ---------------------- 4. 根据排序自动生成区域映射 ----------------------\n",
    "# 预定义区域列表（格式：(x, y, width, height)），按面积从大到小排列\n",
    "predefined_regions = [\n",
    "    (0, 0, 80, 80),    # 面积：6400\n",
    "    (80, 0, 40, 60),   # 面积：2400\n",
    "    (0, 80, 50, 40),   # 面积：2000\n",
    "    (50, 80, 40, 30),  # 面积：1200\n",
    "    (80, 60, 40, 20),  # 面积：800\n",
    "    (90, 80, 30, 20),  # 面积：600\n",
    "    (50, 110, 25, 10), # 面积：250\n",
    "    (75, 110, 20, 10)  # 面积：200\n",
    "]\n",
    "\n",
    "# 如果有自定义映射，可在此处指定，否则使用自动生成的映射\n",
    "self_region_mapping = {\n",
    "    \"Age\": (0, 0, 69, 60),\n",
    "    \"SkinThickness\": (69, 0, 51, 60),\n",
    "    \"BMI\": (0, 60, 59, 40),\n",
    "    \"Pregnancies\": (59, 60, 32, 40),\n",
    "    \"Insulin\": (91, 60, 29, 40),\n",
    "    \"DiabetesPedigreeFunction\": (0, 100, 75, 20),\n",
    "    \"BloodPressure\": (75, 100, 39, 20),\n",
    "    \"Glucose\": (114, 100, 6, 20)\n",
    "}\n",
    "\n",
    "# 自动将预定义区域分配给排序后的特征\n",
    "auto_region_mapping = {}\n",
    "for i, feat in enumerate(ordered_features):\n",
    "    auto_region_mapping[feat] = predefined_regions[i]\n",
    "\n",
    "print(\"自动生成的区域映射：\")\n",
    "for feat, region in auto_region_mapping.items():\n",
    "    print(f\"{feat}: {region}\")\n",
    "\n",
    "# ---------------------- 5. 数值到图像转换函数 ----------------------\n",
    "def create_image_from_features(sample, region_mapping):\n",
    "    \"\"\"\n",
    "    根据单个样本的归一化特征和指定 region_mapping 生成 120x120 灰度图像\n",
    "    \"\"\"\n",
    "    img = Image.new('L', (120, 120), color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 根据各特征值和映射区域绘制对应灰度矩形\n",
    "    for feat in feature_cols:\n",
    "        val = int(sample[feat] * 255)\n",
    "        if feat in region_mapping:\n",
    "            x, y, w, h = region_mapping[feat]\n",
    "            draw.rectangle([x, y, x + w, y + h], fill=val)\n",
    "    return img\n",
    "\n",
    "# 可视化转换后的图像示例\n",
    "sample_img = create_image_from_features(data_norm.iloc[0], auto_region_mapping)\n",
    "plt.imshow(sample_img, cmap='gray')\n",
    "plt.title(\"Sample Converted Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------- 6. 定义 PyTorch 数据集 ----------------------\n",
    "class PimaImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, region_mapping=None):\n",
    "        \"\"\"\n",
    "        df：包含归一化特征和 Outcome 的 DataFrame\n",
    "        transform：数据增强变换\n",
    "        region_mapping：数值到图像转换时使用的区域映射字典\n",
    "        \"\"\"\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.region_mapping = region_mapping if region_mapping is not None else auto_region_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        img = create_image_from_features(sample, self.region_mapping)\n",
    "        label = int(float(sample['Outcome']))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 7. 数据增强与数据加载器 ----------------------\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ---------------------- 8. 进行五次 train_test_split ----------------------\n",
    "# 原始数据部分（合并前的数据）\n",
    "original_data_norm = data_norm.iloc[:dataset_np.shape[0]]\n",
    "# 人工记录部分（全部用于训练）\n",
    "artificial_data_norm = data_norm.iloc[dataset_np.shape[0]:]\n",
    "\n",
    "num_splits = 5\n",
    "final_test_accuracies = []\n",
    "\n",
    "for split in range(1, num_splits + 1):\n",
    "    print(f\"\\n---------------- 第 {split} 次划分 ----------------\")\n",
    "    # 每次先对原始数据进行 shuffle\n",
    "    original_shuffled = original_data_norm.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # 分层划分：80%训练，20%测试（测试集仅保留原始数据）\n",
    "    train_original, test_original = train_test_split(\n",
    "        original_shuffled,\n",
    "        test_size=0.2,\n",
    "        shuffle=True,\n",
    "        stratify=original_shuffled['Outcome']\n",
    "    )\n",
    "    \n",
    "    # 训练集由当前划分的原始数据训练集与所有人工记录组成\n",
    "    train_df = pd.concat([train_original, artificial_data_norm], ignore_index=True)\n",
    "    test_df = test_original\n",
    "    \n",
    "    print(\"训练集样本数:\", train_df.shape[0])\n",
    "    print(\"测试集样本数:\", test_df.shape[0])\n",
    "    \n",
    "    # 创建数据加载器\n",
    "    train_dataset = PimaImageDataset(train_df, transform=train_transform, region_mapping=auto_region_mapping)\n",
    "    test_dataset = PimaImageDataset(test_df, transform=test_transform, region_mapping=auto_region_mapping)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # ---------------------- 9. 定义并微调预训练的 ResNet18 模型 ----------------------\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)  # 两分类任务\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / total_train\n",
    "        train_acc = correct_train / total_train * 100\n",
    "\n",
    "        # 当前划分在测试集上评估\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item() * imgs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (preds == labels).sum().item()\n",
    "        test_loss = running_test_loss / total_test\n",
    "        test_acc = correct_test / total_test * 100\n",
    "        \n",
    "        print(f\"Split {split} - Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # 最终测试评估\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    final_test_acc = correct / total * 100\n",
    "    print(f\"Split {split} Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    final_test_accuracies.append(final_test_acc)\n",
    "\n",
    "# 输出五次划分的测试结果\n",
    "print(\"\\n---------------- 五次划分测试结果 ----------------\")\n",
    "for i, acc in enumerate(final_test_accuracies, 1):\n",
    "    print(f\"Split {i}: Test Accuracy = {acc:.2f}%\")\n",
    "print(f\"Average Test Accuracy: {np.mean(final_test_accuracies):.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
