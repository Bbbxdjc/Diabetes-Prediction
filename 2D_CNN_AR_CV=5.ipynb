{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据形状: (768, 9)\n",
      "人工记录形状: (10000, 9)\n",
      "合并后的数据形状: (10768, 9)\n",
      "ReliefF 计算的特征重要性排序： ['DiabetesPedigreeFunction', 'Age', 'BMI', 'BloodPressure', 'Pregnancies', 'Glucose', 'Insulin', 'SkinThickness']\n",
      "自动生成的区域映射：\n",
      "DiabetesPedigreeFunction: (0, 0, 80, 80)\n",
      "Age: (80, 0, 40, 60)\n",
      "BMI: (0, 80, 50, 40)\n",
      "BloodPressure: (50, 80, 40, 30)\n",
      "Pregnancies: (80, 60, 40, 20)\n",
      "Glucose: (90, 80, 30, 20)\n",
      "Insulin: (50, 110, 25, 10)\n",
      "SkinThickness: (75, 110, 20, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------- Fold 1 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Fold 1 - Epoch 1/20 - Loss: 0.5426 - Train Acc: 71.22% - Test Acc: 79.87%\n",
      "Fold 1 - Epoch 2/20 - Loss: 0.4156 - Train Acc: 80.55% - Test Acc: 81.82%\n",
      "Fold 1 - Epoch 3/20 - Loss: 0.3668 - Train Acc: 83.09% - Test Acc: 80.52%\n",
      "Fold 1 - Epoch 4/20 - Loss: 0.3280 - Train Acc: 84.99% - Test Acc: 84.42%\n",
      "Fold 1 - Epoch 5/20 - Loss: 0.2942 - Train Acc: 86.51% - Test Acc: 85.71%\n",
      "Fold 1 - Epoch 6/20 - Loss: 0.2797 - Train Acc: 87.31% - Test Acc: 88.31%\n",
      "Fold 1 - Epoch 7/20 - Loss: 0.2447 - Train Acc: 89.06% - Test Acc: 92.86%\n",
      "Fold 1 - Epoch 8/20 - Loss: 0.2197 - Train Acc: 90.47% - Test Acc: 92.21%\n",
      "Fold 1 - Epoch 9/20 - Loss: 0.2103 - Train Acc: 90.95% - Test Acc: 93.51%\n",
      "Fold 1 - Epoch 10/20 - Loss: 0.1829 - Train Acc: 92.24% - Test Acc: 92.86%\n",
      "Fold 1 - Epoch 11/20 - Loss: 0.1692 - Train Acc: 92.92% - Test Acc: 92.21%\n",
      "Fold 1 - Epoch 12/20 - Loss: 0.1457 - Train Acc: 94.19% - Test Acc: 92.86%\n",
      "Fold 1 - Epoch 13/20 - Loss: 0.1357 - Train Acc: 94.74% - Test Acc: 93.51%\n",
      "Fold 1 - Epoch 14/20 - Loss: 0.1198 - Train Acc: 95.24% - Test Acc: 96.10%\n",
      "Fold 1 - Epoch 15/20 - Loss: 0.1039 - Train Acc: 95.82% - Test Acc: 96.10%\n",
      "Fold 1 - Epoch 16/20 - Loss: 0.1026 - Train Acc: 95.96% - Test Acc: 95.45%\n",
      "Fold 1 - Epoch 17/20 - Loss: 0.0891 - Train Acc: 96.35% - Test Acc: 96.75%\n",
      "Fold 1 - Epoch 18/20 - Loss: 0.0930 - Train Acc: 96.46% - Test Acc: 95.45%\n",
      "Fold 1 - Epoch 19/20 - Loss: 0.0867 - Train Acc: 96.58% - Test Acc: 98.05%\n",
      "Fold 1 - Epoch 20/20 - Loss: 0.0745 - Train Acc: 97.27% - Test Acc: 98.70%\n",
      "Fold 1 Final Test Accuracy: 98.70%\n",
      "\n",
      "---------------- Fold 2 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Fold 2 - Epoch 1/20 - Loss: 0.5387 - Train Acc: 71.89% - Test Acc: 76.62%\n",
      "Fold 2 - Epoch 2/20 - Loss: 0.4080 - Train Acc: 80.84% - Test Acc: 79.87%\n",
      "Fold 2 - Epoch 3/20 - Loss: 0.3724 - Train Acc: 82.33% - Test Acc: 83.77%\n",
      "Fold 2 - Epoch 4/20 - Loss: 0.3348 - Train Acc: 84.38% - Test Acc: 84.42%\n",
      "Fold 2 - Epoch 5/20 - Loss: 0.3033 - Train Acc: 86.15% - Test Acc: 86.36%\n",
      "Fold 2 - Epoch 6/20 - Loss: 0.2683 - Train Acc: 87.78% - Test Acc: 88.31%\n",
      "Fold 2 - Epoch 7/20 - Loss: 0.2437 - Train Acc: 88.83% - Test Acc: 88.31%\n",
      "Fold 2 - Epoch 8/20 - Loss: 0.2142 - Train Acc: 90.42% - Test Acc: 89.61%\n",
      "Fold 2 - Epoch 9/20 - Loss: 0.2010 - Train Acc: 91.44% - Test Acc: 91.56%\n",
      "Fold 2 - Epoch 10/20 - Loss: 0.1872 - Train Acc: 92.14% - Test Acc: 94.16%\n",
      "Fold 2 - Epoch 11/20 - Loss: 0.1687 - Train Acc: 92.87% - Test Acc: 91.56%\n",
      "Fold 2 - Epoch 12/20 - Loss: 0.1456 - Train Acc: 93.87% - Test Acc: 94.81%\n",
      "Fold 2 - Epoch 13/20 - Loss: 0.1316 - Train Acc: 94.62% - Test Acc: 95.45%\n",
      "Fold 2 - Epoch 14/20 - Loss: 0.1209 - Train Acc: 94.96% - Test Acc: 95.45%\n",
      "Fold 2 - Epoch 15/20 - Loss: 0.1203 - Train Acc: 95.11% - Test Acc: 96.75%\n",
      "Fold 2 - Epoch 16/20 - Loss: 0.1114 - Train Acc: 95.85% - Test Acc: 94.81%\n",
      "Fold 2 - Epoch 17/20 - Loss: 0.0932 - Train Acc: 96.47% - Test Acc: 97.40%\n",
      "Fold 2 - Epoch 18/20 - Loss: 0.0812 - Train Acc: 96.74% - Test Acc: 98.05%\n",
      "Fold 2 - Epoch 19/20 - Loss: 0.0926 - Train Acc: 96.51% - Test Acc: 99.35%\n",
      "Fold 2 - Epoch 20/20 - Loss: 0.0672 - Train Acc: 97.44% - Test Acc: 99.35%\n",
      "Fold 2 Final Test Accuracy: 99.35%\n",
      "\n",
      "---------------- Fold 3 ----------------\n",
      "训练集样本数: 10614\n",
      "测试集样本数: 154\n",
      "Fold 3 - Epoch 1/20 - Loss: 0.5410 - Train Acc: 71.95% - Test Acc: 74.03%\n",
      "Fold 3 - Epoch 2/20 - Loss: 0.4206 - Train Acc: 80.50% - Test Acc: 78.57%\n",
      "Fold 3 - Epoch 3/20 - Loss: 0.3582 - Train Acc: 83.07% - Test Acc: 81.17%\n",
      "Fold 3 - Epoch 4/20 - Loss: 0.3243 - Train Acc: 84.72% - Test Acc: 77.27%\n",
      "Fold 3 - Epoch 5/20 - Loss: 0.2955 - Train Acc: 86.18% - Test Acc: 79.87%\n",
      "Fold 3 - Epoch 6/20 - Loss: 0.2696 - Train Acc: 87.94% - Test Acc: 84.42%\n",
      "Fold 3 - Epoch 7/20 - Loss: 0.2346 - Train Acc: 89.40% - Test Acc: 86.36%\n",
      "Fold 3 - Epoch 8/20 - Loss: 0.2197 - Train Acc: 89.99% - Test Acc: 88.31%\n",
      "Fold 3 - Epoch 9/20 - Loss: 0.1993 - Train Acc: 91.33% - Test Acc: 87.66%\n",
      "Fold 3 - Epoch 10/20 - Loss: 0.1814 - Train Acc: 92.41% - Test Acc: 90.91%\n",
      "Fold 3 - Epoch 11/20 - Loss: 0.1643 - Train Acc: 93.13% - Test Acc: 90.26%\n",
      "Fold 3 - Epoch 12/20 - Loss: 0.1409 - Train Acc: 94.35% - Test Acc: 90.91%\n",
      "Fold 3 - Epoch 13/20 - Loss: 0.1278 - Train Acc: 94.80% - Test Acc: 95.45%\n",
      "Fold 3 - Epoch 14/20 - Loss: 0.1158 - Train Acc: 95.36% - Test Acc: 95.45%\n",
      "Fold 3 - Epoch 15/20 - Loss: 0.1072 - Train Acc: 95.70% - Test Acc: 96.10%\n",
      "Fold 3 - Epoch 16/20 - Loss: 0.0987 - Train Acc: 96.27% - Test Acc: 96.75%\n",
      "Fold 3 - Epoch 17/20 - Loss: 0.0910 - Train Acc: 96.45% - Test Acc: 97.40%\n",
      "Fold 3 - Epoch 18/20 - Loss: 0.0810 - Train Acc: 97.00% - Test Acc: 96.75%\n",
      "Fold 3 - Epoch 19/20 - Loss: 0.0664 - Train Acc: 97.63% - Test Acc: 98.70%\n",
      "Fold 3 - Epoch 20/20 - Loss: 0.0800 - Train Acc: 96.89% - Test Acc: 97.40%\n",
      "Fold 3 Final Test Accuracy: 97.40%\n",
      "\n",
      "---------------- Fold 4 ----------------\n",
      "训练集样本数: 10615\n",
      "测试集样本数: 153\n",
      "Fold 4 - Epoch 1/20 - Loss: 0.5603 - Train Acc: 70.26% - Test Acc: 63.40%\n",
      "Fold 4 - Epoch 2/20 - Loss: 0.4186 - Train Acc: 79.87% - Test Acc: 78.43%\n",
      "Fold 4 - Epoch 3/20 - Loss: 0.3636 - Train Acc: 82.84% - Test Acc: 76.47%\n",
      "Fold 4 - Epoch 4/20 - Loss: 0.3343 - Train Acc: 84.48% - Test Acc: 75.82%\n",
      "Fold 4 - Epoch 5/20 - Loss: 0.3040 - Train Acc: 86.07% - Test Acc: 83.66%\n",
      "Fold 4 - Epoch 6/20 - Loss: 0.2628 - Train Acc: 88.28% - Test Acc: 82.35%\n",
      "Fold 4 - Epoch 7/20 - Loss: 0.2344 - Train Acc: 89.71% - Test Acc: 86.27%\n",
      "Fold 4 - Epoch 8/20 - Loss: 0.2181 - Train Acc: 90.59% - Test Acc: 86.93%\n",
      "Fold 4 - Epoch 9/20 - Loss: 0.1952 - Train Acc: 91.41% - Test Acc: 89.54%\n",
      "Fold 4 - Epoch 10/20 - Loss: 0.1694 - Train Acc: 92.80% - Test Acc: 87.58%\n",
      "Fold 4 - Epoch 11/20 - Loss: 0.1591 - Train Acc: 93.15% - Test Acc: 90.85%\n",
      "Fold 4 - Epoch 12/20 - Loss: 0.1458 - Train Acc: 94.02% - Test Acc: 88.89%\n",
      "Fold 4 - Epoch 13/20 - Loss: 0.1404 - Train Acc: 94.54% - Test Acc: 92.16%\n",
      "Fold 4 - Epoch 14/20 - Loss: 0.1263 - Train Acc: 94.81% - Test Acc: 90.85%\n",
      "Fold 4 - Epoch 15/20 - Loss: 0.1094 - Train Acc: 95.61% - Test Acc: 95.42%\n",
      "Fold 4 - Epoch 16/20 - Loss: 0.0987 - Train Acc: 95.90% - Test Acc: 96.08%\n",
      "Fold 4 - Epoch 17/20 - Loss: 0.0943 - Train Acc: 96.52% - Test Acc: 96.08%\n",
      "Fold 4 - Epoch 18/20 - Loss: 0.0804 - Train Acc: 97.08% - Test Acc: 93.46%\n",
      "Fold 4 - Epoch 19/20 - Loss: 0.0761 - Train Acc: 97.15% - Test Acc: 94.77%\n",
      "Fold 4 - Epoch 20/20 - Loss: 0.0789 - Train Acc: 97.00% - Test Acc: 96.08%\n",
      "Fold 4 Final Test Accuracy: 96.08%\n",
      "\n",
      "---------------- Fold 5 ----------------\n",
      "训练集样本数: 10615\n",
      "测试集样本数: 153\n",
      "Fold 5 - Epoch 1/20 - Loss: 0.5438 - Train Acc: 71.40% - Test Acc: 71.90%\n",
      "Fold 5 - Epoch 2/20 - Loss: 0.4294 - Train Acc: 80.08% - Test Acc: 72.55%\n",
      "Fold 5 - Epoch 3/20 - Loss: 0.3691 - Train Acc: 82.65% - Test Acc: 69.28%\n",
      "Fold 5 - Epoch 4/20 - Loss: 0.3364 - Train Acc: 84.16% - Test Acc: 77.12%\n",
      "Fold 5 - Epoch 5/20 - Loss: 0.3090 - Train Acc: 85.66% - Test Acc: 84.31%\n",
      "Fold 5 - Epoch 6/20 - Loss: 0.2777 - Train Acc: 87.15% - Test Acc: 78.43%\n",
      "Fold 5 - Epoch 7/20 - Loss: 0.2558 - Train Acc: 88.24% - Test Acc: 79.74%\n",
      "Fold 5 - Epoch 8/20 - Loss: 0.2233 - Train Acc: 90.28% - Test Acc: 81.70%\n",
      "Fold 5 - Epoch 9/20 - Loss: 0.2219 - Train Acc: 90.09% - Test Acc: 85.62%\n",
      "Fold 5 - Epoch 10/20 - Loss: 0.1877 - Train Acc: 91.98% - Test Acc: 88.89%\n",
      "Fold 5 - Epoch 11/20 - Loss: 0.1685 - Train Acc: 92.52% - Test Acc: 88.24%\n",
      "Fold 5 - Epoch 12/20 - Loss: 0.1566 - Train Acc: 93.20% - Test Acc: 91.50%\n",
      "Fold 5 - Epoch 13/20 - Loss: 0.1488 - Train Acc: 93.97% - Test Acc: 92.81%\n",
      "Fold 5 - Epoch 14/20 - Loss: 0.1321 - Train Acc: 94.47% - Test Acc: 91.50%\n",
      "Fold 5 - Epoch 15/20 - Loss: 0.1252 - Train Acc: 95.00% - Test Acc: 95.42%\n",
      "Fold 5 - Epoch 16/20 - Loss: 0.1074 - Train Acc: 95.88% - Test Acc: 91.50%\n",
      "Fold 5 - Epoch 17/20 - Loss: 0.1108 - Train Acc: 95.52% - Test Acc: 95.42%\n",
      "Fold 5 - Epoch 18/20 - Loss: 0.0959 - Train Acc: 96.20% - Test Acc: 94.77%\n",
      "Fold 5 - Epoch 19/20 - Loss: 0.0800 - Train Acc: 96.90% - Test Acc: 94.12%\n",
      "Fold 5 - Epoch 20/20 - Loss: 0.0775 - Train Acc: 97.06% - Test Acc: 95.42%\n",
      "Fold 5 Final Test Accuracy: 95.42%\n",
      "\n",
      "---------------- Cross Validation Results ----------------\n",
      "Fold 1: Test Accuracy = 98.70%\n",
      "Fold 2: Test Accuracy = 99.35%\n",
      "Fold 3: Test Accuracy = 97.40%\n",
      "Fold 4: Test Accuracy = 96.08%\n",
      "Fold 5: Test Accuracy = 95.42%\n",
      "Average Test Accuracy: 97.39%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# ===================== Artificial Record 数据处理 =====================\n",
    "def create_artificial_records(dataset, num_artificial_records=10000):\n",
    "    artificial_records = []\n",
    "    \n",
    "    # 将数据按 Outcome 分为糖尿病和非糖尿病\n",
    "    diabetic = dataset[dataset[:, -1] == 1]\n",
    "    non_diabetic = dataset[dataset[:, -1] == 0]\n",
    "    \n",
    "    for partition in [diabetic, non_diabetic]:\n",
    "        # 根据年龄分组：小于40为年轻组，大于等于40为年长组\n",
    "        young = partition[partition[:, -2] < 40]\n",
    "        old = partition[partition[:, -2] >= 40]\n",
    "        \n",
    "        for age_group in [young, old]:\n",
    "            # 分为孕妇组和非孕妇组（孕次>0为孕妇）\n",
    "            pregnant = age_group[age_group[:, 0] > 0]\n",
    "            non_pregnant = age_group[age_group[:, 0] == 0]\n",
    "            \n",
    "            for group in [pregnant, non_pregnant]:\n",
    "                if len(group) > 0:  # 确保组非空\n",
    "                    for _ in range(num_artificial_records // 8):\n",
    "                        new_record = group[np.random.randint(len(group))].copy()\n",
    "                        \n",
    "                        # 在 Glucose 和 Insulin 上做微小调整（保持反比关系）\n",
    "                        glucose_change = np.random.uniform(-10, 10)\n",
    "                        new_record[1] += glucose_change\n",
    "                        new_record[4] -= glucose_change * 0.5\n",
    "                        \n",
    "                        # 在 SkinThickness 和 BMI 上做微小调整\n",
    "                        skin_change = np.random.uniform(-5, 5)\n",
    "                        new_record[3] += skin_change\n",
    "                        new_record[5] += skin_change * 0.1\n",
    "                        \n",
    "                        artificial_records.append(new_record)\n",
    "    \n",
    "    return np.array(artificial_records)\n",
    "\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# ---------------------- 0. 数据加载与清洗 ----------------------\n",
    "# 假设文件中列顺序为：Pregnancies, Glucose, BloodPressure, SkinThickness,\n",
    "# Insulin, BMI, DiabetesPedigreeFunction, Age, Outcome\n",
    "data = pd.read_csv('diabetes_dataset_1.csv')\n",
    "\n",
    "# 将部分特征中可能出现的0（视为缺失值）替换为中位数\n",
    "cols_to_replace = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "for col in cols_to_replace:\n",
    "    data[col] = data[col].replace(0, np.nan)\n",
    "    data[col].fillna(data[col].median(), inplace=True)\n",
    "\n",
    "# ---------------------- 1. 生成原始数据与人工记录，并合并数据 ----------------------\n",
    "# 将原始数据转换为 numpy 数组\n",
    "dataset_np = data.values\n",
    "print(\"原始数据形状:\", dataset_np.shape)\n",
    "\n",
    "# 生成人工记录（基于原始数据生成）\n",
    "artificial_dataset = create_artificial_records(dataset_np)\n",
    "print(\"人工记录形状:\", artificial_dataset.shape)\n",
    "\n",
    "# 合并原始数据和部分人工记录（此处只取前 10000 条人工记录）\n",
    "combined_dataset_np = np.vstack((dataset_np, artificial_dataset[:10000]))\n",
    "print(\"合并后的数据形状:\", combined_dataset_np.shape)\n",
    "\n",
    "# 转换为 DataFrame，并保持原有列名\n",
    "combined_data = pd.DataFrame(combined_dataset_np, columns=data.columns)\n",
    "\n",
    "# ---------------------- 2. 对所有特征进行 min–max 归一化 ----------------------\n",
    "# 仅对特征列归一化，Outcome 保持不变\n",
    "feature_cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "                \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "\n",
    "data_norm = combined_data.copy()\n",
    "for col in feature_cols:\n",
    "    min_val = data_norm[col].min()\n",
    "    max_val = data_norm[col].max()\n",
    "    data_norm[col] = (data_norm[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "# ---------------------- 3. 利用 ReliefF 计算特征重要性 ----------------------\n",
    "from skrebate import ReliefF\n",
    "\n",
    "X = data_norm[feature_cols].values\n",
    "y = data_norm['Outcome'].values.astype(int)\n",
    "\n",
    "relief = ReliefF(n_neighbors=10)\n",
    "relief.fit(X, y)\n",
    "importance_scores = relief.feature_importances_\n",
    "\n",
    "# 按重要性降序排列，得到特征名称排序\n",
    "ordered_indices = np.argsort(importance_scores)[::-1]\n",
    "ordered_features = [feature_cols[i] for i in ordered_indices]\n",
    "print(\"ReliefF 计算的特征重要性排序：\", ordered_features)\n",
    "\n",
    "# ---------------------- 4. 根据排序自动生成区域映射 ----------------------\n",
    "predefined_regions = [\n",
    "    (0, 0, 80, 80),    # 面积：6400\n",
    "    (80, 0, 40, 60),   # 面积：2400\n",
    "    (0, 80, 50, 40),   # 面积：2000\n",
    "    (50, 80, 40, 30),  # 面积：1200\n",
    "    (80, 60, 40, 20),  # 面积：800\n",
    "    (90, 80, 30, 20),  # 面积：600\n",
    "    (50, 110, 25, 10), # 面积：250\n",
    "    (75, 110, 20, 10)  # 面积：200\n",
    "]\n",
    "\n",
    "self_region_mapping = {\n",
    "    \"Age\": (0, 0, 69, 60),\n",
    "    \"SkinThickness\": (69, 0, 51, 60),\n",
    "    \"BMI\": (0, 60, 59, 40),\n",
    "    \"Pregnancies\": (59, 60, 32, 40),\n",
    "    \"Insulin\": (91, 60, 29, 40),\n",
    "    \"DiabetesPedigreeFunction\": (0, 100, 75, 20),\n",
    "    \"BloodPressure\": (75, 100, 39, 20),\n",
    "    \"Glucose\": (114, 100, 6, 20)\n",
    "}\n",
    "\n",
    "auto_region_mapping = {}\n",
    "for i, feat in enumerate(ordered_features):\n",
    "    auto_region_mapping[feat] = predefined_regions[i]\n",
    "\n",
    "print(\"自动生成的区域映射：\")\n",
    "for feat, region in auto_region_mapping.items():\n",
    "    print(f\"{feat}: {region}\")\n",
    "\n",
    "# ---------------------- 5. 数值到图像转换函数 ----------------------\n",
    "def create_image_from_features(sample, region_mapping):\n",
    "    \"\"\"\n",
    "    根据单个样本的归一化特征和指定 region_mapping 生成 120x120 灰度图像\n",
    "    \"\"\"\n",
    "    img = Image.new('L', (120, 120), color=0)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    for feat in feature_cols:\n",
    "        val = int(sample[feat] * 255)\n",
    "        if feat in region_mapping:\n",
    "            x, y, w, h = region_mapping[feat]\n",
    "            draw.rectangle([x, y, x + w, y + h], fill=val)\n",
    "    return img\n",
    "\n",
    "# 可视化转换后的图像示例\n",
    "sample_img = create_image_from_features(data_norm.iloc[0], auto_region_mapping)\n",
    "plt.imshow(sample_img, cmap='gray')\n",
    "plt.title(\"Sample Converted Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------- 6. 定义 PyTorch 数据集 ----------------------\n",
    "class PimaImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None, region_mapping=None):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        self.region_mapping = region_mapping if region_mapping is not None else auto_region_mapping\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.df.iloc[idx]\n",
    "        img = create_image_from_features(sample, self.region_mapping)\n",
    "        label = int(float(sample['Outcome']))\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        else:\n",
    "            img = transforms.ToTensor()(img)\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 7. 数据增强与数据加载器 ----------------------\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomAffine(0, translate=(0.1, 0.1)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Lambda(convert_to_rgb),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# ---------------------- 8. 五折交叉验证 ----------------------\n",
    "# 注意：这里仍然保持原有目标——测试集仅来自原始数据，人工记录始终加入训练\n",
    "original_data_norm = data_norm.iloc[:dataset_np.shape[0]]\n",
    "artificial_data_norm = data_norm.iloc[dataset_np.shape[0]:]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "fold_idx = 1\n",
    "fold_accuracies = []\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for train_index, test_index in skf.split(original_data_norm, original_data_norm['Outcome']):\n",
    "    print(f\"\\n---------------- Fold {fold_idx} ----------------\")\n",
    "    # 当前折中原始数据的训练和测试部分\n",
    "    train_original_fold = original_data_norm.iloc[train_index]\n",
    "    test_original_fold = original_data_norm.iloc[test_index]\n",
    "    \n",
    "    # 训练集由当前折的原始数据和所有人工记录组成\n",
    "    train_df_fold = pd.concat([train_original_fold, artificial_data_norm], ignore_index=True)\n",
    "    test_df_fold = test_original_fold\n",
    "    \n",
    "    print(\"训练集样本数:\", train_df_fold.shape[0])\n",
    "    print(\"测试集样本数:\", test_df_fold.shape[0])\n",
    "    \n",
    "    train_dataset = PimaImageDataset(train_df_fold, transform=train_transform, region_mapping=auto_region_mapping)\n",
    "    test_dataset = PimaImageDataset(test_df_fold, transform=test_transform, region_mapping=auto_region_mapping)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    # ---------------------- 9. 定义并微调预训练的 ResNet18 模型 ----------------------\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    num_features = model.fc.in_features\n",
    "    model.fc = nn.Linear(num_features, 2)  # 二分类任务\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "    \n",
    "    num_epochs = 20\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (preds == labels).sum().item()\n",
    "        \n",
    "        epoch_loss = running_loss / total_train\n",
    "        train_acc = correct_train / total_train * 100\n",
    "        \n",
    "        # 在当前折测试集上评估\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_loader:\n",
    "                imgs, labels = imgs.to(device), labels.to(device)\n",
    "                outputs = model(imgs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                running_test_loss += loss.item() * imgs.size(0)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                total_test += labels.size(0)\n",
    "                correct_test += (preds == labels).sum().item()\n",
    "        test_loss = running_test_loss / total_test\n",
    "        test_acc = correct_test / total_test * 100\n",
    "        \n",
    "        print(f\"Fold {fold_idx} - Epoch {epoch+1}/{num_epochs} - Loss: {epoch_loss:.4f} - Train Acc: {train_acc:.2f}% - Test Acc: {test_acc:.2f}%\")\n",
    "    \n",
    "    # 记录当前折的最终测试准确率\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in test_loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (preds == labels).sum().item()\n",
    "    final_test_acc = correct / total * 100\n",
    "    print(f\"Fold {fold_idx} Final Test Accuracy: {final_test_acc:.2f}%\")\n",
    "    fold_accuracies.append(final_test_acc)\n",
    "    \n",
    "    fold_idx += 1\n",
    "\n",
    "print(\"\\n---------------- Cross Validation Results ----------------\")\n",
    "for i, acc in enumerate(fold_accuracies, 1):\n",
    "    print(f\"Fold {i}: Test Accuracy = {acc:.2f}%\")\n",
    "print(f\"Average Test Accuracy: {np.mean(fold_accuracies):.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tor_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
