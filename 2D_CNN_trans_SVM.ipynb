{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReliefF 计算的特征重要性排序： ['Glucose', 'BMI', 'SkinThickness', 'Pregnancies', 'Age', 'DiabetesPedigreeFunction', 'BloodPressure', 'Insulin']\n",
      "自动生成的区域映射：\n",
      "Glucose: (0, 0, 80, 80)\n",
      "BMI: (80, 0, 40, 60)\n",
      "SkinThickness: (0, 80, 50, 40)\n",
      "Pregnancies: (50, 80, 40, 30)\n",
      "Age: (80, 60, 40, 20)\n",
      "DiabetesPedigreeFunction: (90, 80, 30, 20)\n",
      "BloodPressure: (50, 110, 25, 10)\n",
      "Insulin: (75, 110, 20, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正在提取训练集特征...\n",
      "训练集特征形状： (3072, 512)\n",
      "训练集特征形状： (3072, 2048)\n",
      "正在提取测试集特征...\n",
      "测试集特征形状： (768, 512)\n",
      "测试集特征形状： (768, 2048)\n",
      "SVM Test Accuracy: 74.35%\n",
      "SVM ROC AUC: 0.8156\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X.shape[1] = 512 should be equal to 500, the number of features at training time",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-51eaa8a14b25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    267\u001b[0m \u001b[0mfeats_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[1;31m# SVM预测\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m \u001b[0msvm_preds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeats_np\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m \u001b[0mimages_np\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    622\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    623\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 624\u001b[1;33m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    625\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \"\"\"\n\u001b[1;32m--> 342\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    343\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Anaconda3\\envs\\pytorch\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    493\u001b[0m             raise ValueError(\"X.shape[1] = %d should be equal to %d, \"\n\u001b[0;32m    494\u001b[0m                              \u001b[1;34m\"the number of features at training time\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 495\u001b[1;33m                              (X.shape[1], self.shape_fit_[1]))\n\u001b[0m\u001b[0;32m    496\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X.shape[1] = 512 should be equal to 500, the number of features at training time"
     ]
    }
   ],
   "source": [
    "#import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# ---------------------- 1. 数据加载与归一化 ----------------------\n",
    "# CSV 文件包含的特征\n",
    "feature_cols = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\",\n",
    "                \"Insulin\", \"BMI\", \"DiabetesPedigreeFunction\", \"Age\"]\n",
    "\n",
    "data = pd.read_csv('diabetes_dataset_1.csv')\n",
    "\n",
    "# 对所有特征进行 min–max 归一化\n",
    "data_norm = data.copy()\n",
    "for col in feature_cols:\n",
    "    min_val = data[col].min()\n",
    "    max_val = data[col].max()\n",
    "    data_norm[col] = (data[col] - min_val) / (max_val - min_val)\n",
    "\n",
    "# ---------------------- 2. 利用 ReliefF 自动计算特征重要性 ----------------------\n",
    "# 需要安装 skrebate：pip install skrebate\n",
    "from skrebate import ReliefF\n",
    "\n",
    "X = data_norm[feature_cols].values\n",
    "y = data_norm['Outcome'].values\n",
    "\n",
    "relief = ReliefF(n_neighbors=10)\n",
    "relief.fit(X, y)\n",
    "importance_scores = relief.feature_importances_\n",
    "\n",
    "# 按照重要性降序排列，得到特征名称排序\n",
    "ordered_indices = np.argsort(importance_scores)[::-1]\n",
    "ordered_features = [feature_cols[i] for i in ordered_indices]\n",
    "print(\"ReliefF 计算的特征重要性排序：\", ordered_features)\n",
    "\n",
    "# ---------------------- 3. 根据排序自动生成区域映射 ----------------------\n",
    "# 定义预先设计好的区域列表，按面积从大到小排列（格式：(x, y, width, height)）\n",
    "predefined_regions = [\n",
    "    (0, 0, 80, 80),    # 面积：80x80=6400，分配给最重要的特征\n",
    "    (80, 0, 40, 60),   # 面积：40x60=2400\n",
    "    (0, 80, 50, 40),   # 面积：50x40=2000\n",
    "    (50, 80, 40, 30),  # 面积：40x30=1200\n",
    "    (80, 60, 40, 20),  # 面积：40x20=800\n",
    "    (90, 80, 30, 20),  # 面积：30x20=600\n",
    "    (50, 110, 25, 10), # 面积：25x10=250\n",
    "    (75, 110, 20, 10)  # 面积：20x10=200\n",
    "]\n",
    "\n",
    "# 如果有自定义映射，可在此处指定，否则使用自动生成的映射\n",
    "self_region_mapping = {\n",
    "    \"Age\": (0, 0, 69, 60),                     # Feature_7\n",
    "    \"SkinThickness\": (69, 0, 51, 60),          # Feature_3\n",
    "    \"BMI\": (0, 60, 59, 40),                    # Feature_5\n",
    "    \"Pregnancies\": (59, 60, 32, 40),           # Feature_0\n",
    "    \"Insulin\": (91, 60, 29, 40),               # Feature_4\n",
    "    \"DiabetesPedigreeFunction\": (0, 100, 75, 20),  # Feature_6\n",
    "    \"BloodPressure\": (75, 100, 39, 20),        # Feature_2\n",
    "    \"Glucose\": (114, 100, 6, 20)               # Feature_1\n",
    "}\n",
    "\n",
    "# 自动将预定义区域分配给排序后的特征\n",
    "auto_region_mapping = {}\n",
    "for i, feat in enumerate(ordered_features):\n",
    "    auto_region_mapping[feat] = predefined_regions[i]\n",
    "\n",
    "print(\"自动生成的区域映射：\")\n",
    "for feat, region in auto_region_mapping.items():\n",
    "    print(f\"{feat}: {region}\")\n",
    "\n",
    "# ---------------------- 4. 数值到图像转换函数 ----------------------\n",
    "def create_image_from_features(sample, region_mapping):\n",
    "    \"\"\"\n",
    "    根据单个样本的归一化特征和给定的 region_mapping 生成 120x120 灰度图像\n",
    "    \"\"\"\n",
    "    img = Image.new('L', (120, 120), color=0)  # 创建黑底图\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # 对于每个特征，根据 mapping 中的区域将值映射到 0-255 灰度值\n",
    "    for feat in feature_cols:\n",
    "        val = int(sample[feat] * 255)\n",
    "        if feat in region_mapping:\n",
    "            x, y, w, h = region_mapping[feat]\n",
    "            draw.rectangle([x, y, x + w, y + h], fill=val)\n",
    "    return img\n",
    "\n",
    "# 可视化查看一个样本转换后的图像\n",
    "sample_img = create_image_from_features(data_norm.iloc[0], auto_region_mapping)\n",
    "plt.imshow(sample_img, cmap='gray')\n",
    "plt.title(\"Sample Converted Image\")\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# ---------------------- 5. 定义 PyTorch 数据集 ----------------------\n",
    "class PimaImageDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        df：包含归一化特征及 Outcome 的 DataFrame\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img = self.X[idx]\n",
    "        label = int(self.y[idx])\n",
    "        img = transforms.ToTensor()(img)\n",
    "        return img, label\n",
    "\n",
    "# ---------------------- 6. 数据增强与数据加载器 ----------------------\n",
    "def convert_to_rgb(img):\n",
    "    return img.convert('RGB')\n",
    "\n",
    "# 一维转二维\n",
    "def changeToTwoD(dataset, region_mapping):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for idx in range(dataset.shape[0]):\n",
    "        img = convert_to_rgb(create_image_from_features(dataset.iloc[idx], region_mapping))\n",
    "\n",
    "        resize = transforms.Resize(size=(224, 224))\n",
    "        img = resize.forward(img)\n",
    "\n",
    "        label = int(dataset.iloc[idx]['Outcome'])\n",
    "        features.append(img)\n",
    "        labels.append(label)\n",
    "    return features, labels\n",
    "\n",
    "# 这里对2D图像通过几何变换进行数据增广\n",
    "def create_artificial_records(img_features, img_labels):\n",
    "    artificial_features = []\n",
    "    artificial_labels = []\n",
    "    for i, imfe in enumerate(img_features):\n",
    "\n",
    "        img = [0] * 4\n",
    "\n",
    "        flip = transforms.RandomHorizontalFlip(p=1)\n",
    "        rotate = transforms.RandomRotation(30)\n",
    "        scale = transforms.Resize(size=(int(120 * random.uniform(0.9,1.1)), int(120 * random.uniform(0.9,1.1))))\n",
    "        translate = transforms.RandomAffine(0, translate=(0.1, 0.1))\n",
    "\n",
    "        resize = transforms.Resize(size=(224, 224))\n",
    "\n",
    "        img[0] = flip.forward(imfe)\n",
    "        img[1] = rotate.forward(imfe)\n",
    "        img[2] = scale.forward(imfe)\n",
    "        img[3] = translate.forward(imfe)\n",
    "        img = [resize.forward(_im) for _im in img]\n",
    "        artificial_features += img\n",
    "        artificial_labels += [img_labels[i]] * 4\n",
    "    return artificial_features, artificial_labels\n",
    "\n",
    "img_features, img_labels = changeToTwoD(data_norm, auto_region_mapping)\n",
    "aug_img_features, aug_img_labels = create_artificial_records(img_features, img_labels)\n",
    "all_features = img_features + aug_img_features\n",
    "all_labels = img_labels + aug_img_labels\n",
    "\n",
    "# 下面还要改改 ------ 已经改好了\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    all_features, all_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = PimaImageDataset(X_train, y_train)\n",
    "test_dataset = PimaImageDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "\n",
    "# ---------------------- 7. 使用预训练的 ResNet18 和 ResNet50 作为特征提取器 ----------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# 加载预训练的 ResNet18 模型，并去掉最后的全连接层\n",
    "model_18 = models.resnet18(pretrained=True)\n",
    "model_18.fc = nn.Identity()  # 将最后的全连接层置为恒等映射\n",
    "model_18 = model_18.to(device)\n",
    "model_18.eval()  # 固定特征提取器\n",
    "\n",
    "# 加载预训练的 ResNet50 模型，并去掉最后的全连接层\n",
    "model_50 = models.resnet50(pretrained=True)\n",
    "model_50.fc = nn.Identity()  # 将最后的全连接层置为恒等映射\n",
    "model_50 = model_50.to(device)\n",
    "model_50.eval()  # 固定特征提取器\n",
    "\n",
    "# ---------------------- 8. 提取训练集和测试集的特征 ----------------------\n",
    "import time\n",
    "\n",
    "def extract_features(data_loader, model, device):\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in data_loader:\n",
    "            imgs = imgs.to(device)\n",
    "            feats = model(imgs)  # 得到特征向量\n",
    "            features_list.append(feats.cpu().numpy())\n",
    "            labels_list.append(labels.cpu().numpy())\n",
    "    features = np.concatenate(features_list, axis=0)\n",
    "    labels = np.concatenate(labels_list, axis=0)\n",
    "    return features, labels\n",
    "\n",
    "print(\"正在提取训练集特征...\")\n",
    "train_features_18, train_labels = extract_features(train_loader, model_18, device)\n",
    "train_features_50, train_labels = extract_features(train_loader, model_50, device)\n",
    "print(\"训练集特征形状：\", train_features_18.shape)\n",
    "print(\"训练集特征形状：\", train_features_50.shape)\n",
    "\n",
    "print(\"正在提取测试集特征...\")\n",
    "test_features_18, test_labels = extract_features(test_loader, model_18, device)\n",
    "test_features_50, test_labels = extract_features(test_loader, model_50, device)\n",
    "print(\"测试集特征形状：\", test_features_18.shape)\n",
    "print(\"测试集特征形状：\", test_features_50.shape)\n",
    "\n",
    "# 将18和50的训练features合并\n",
    "train_features = np.concatenate((np.array(train_features_18), np.array(train_features_50)), axis=1)\n",
    "test_features = np.concatenate((np.array(test_features_18), np.array(test_features_50)), axis=1)\n",
    "\n",
    "### 这里第二次使用reliefF对2560个特征进行选择，选出前500个 ###\n",
    "relief_2 = ReliefF(n_neighbors=10)\n",
    "relief_2.fit(train_features, train_labels)\n",
    "importance_scores_2 = relief_2.feature_importances_\n",
    "\n",
    "# 按照重要性降序排列，得到特征名称排序\n",
    "ordered_indices_2 = np.argsort(importance_scores_2)[::-1]\n",
    "# 选择前500个重要特征\n",
    "selected_train_features = train_features[:, ordered_indices_2[:500]]\n",
    "selected_test_features = test_features[:, ordered_indices_2[:500]]\n",
    "\n",
    "# ---------------------- 9. 使用 SVM 进行分类 ----------------------\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "\n",
    "# 使用线性核的 SVM 进行训练\n",
    "svm_clf = SVC(kernel='linear', probability=True, random_state=42)\n",
    "svm_clf.fit(selected_train_features, train_labels)\n",
    "\n",
    "# 在测试集上预测\n",
    "test_preds = svm_clf.predict(selected_test_features)\n",
    "test_acc = accuracy_score(test_labels, test_preds)\n",
    "print(f\"SVM Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "# 计算 ROC AUC（假设二分类问题，使用预测概率）\n",
    "test_probs = svm_clf.predict_proba(selected_test_features)[:, 1]\n",
    "roc_auc = roc_auc_score(test_labels, test_probs)\n",
    "print(f\"SVM ROC AUC: {roc_auc:.4f}\")\n",
    "\n",
    "# ---------------------- 10. 可视化部分 ----------------------\n",
    "# 取测试集中的一个 batch，使用 CNN 提取特征后，用 SVM 得到预测结果，展示图像\n",
    "import math\n",
    "\n",
    "model_18.eval()\n",
    "model_50.eval()\n",
    "data_iter = iter(test_loader)\n",
    "images, labels = next(data_iter)\n",
    "images = images.to(device)\n",
    "with torch.no_grad():\n",
    "    feats = model_18(images)\n",
    "feats_np = feats.cpu().numpy()\n",
    "# SVM预测\n",
    "svm_preds = svm_clf.predict(feats_np)\n",
    "\n",
    "images_np = images.cpu().numpy().transpose((0, 2, 3, 1))\n",
    "\n",
    "batch_size = images_np.shape[0]\n",
    "cols = 8\n",
    "rows = math.ceil(batch_size / cols)\n",
    "plt.figure(figsize=(15, 2.5 * rows))\n",
    "for i in range(batch_size):\n",
    "    plt.subplot(rows, cols, i+1)\n",
    "    plt.imshow(images_np[i])\n",
    "    plt.title(f\"Pred: {svm_preds[i]}\\nTrue: {labels[i].item()}\", fontsize=8)\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
